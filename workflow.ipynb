{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcd5438",
   "metadata": {},
   "source": [
    "### Entity Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc4ad1",
   "metadata": {},
   "source": [
    "#### module initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8262eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import srsly\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup module paths\n",
    "m_ner_model_path = \"./Models/METHOD_NER\"\n",
    "a_ner_model_path = \"./Models/ACTIVITY_NER\"\n",
    "g_ner_model_path = \"./Models/GOAL_NER\"\n",
    "\n",
    "# Setup input and output paths\n",
    "ee_input_path = \"./Dataset/example_subset_20.jsonl\"\n",
    "ee_output_path = \"./Dataset/example_subset_20_EE.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66cfd1f",
   "metadata": {},
   "source": [
    "#### module functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f09eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER(model_path, in_data, entity):\n",
    "    print(\"NER for:\", entity)\n",
    "    ner_model = spacy.load(model_path)\n",
    "    annotated_data = []\n",
    "    for row in tqdm(in_data):\n",
    "        sent_nlp = ner_model(row[\"text\"])\n",
    "        ner_spans = [{\"start_char\": span.start_char, \"end_char\": span.end_char, \"token_start\":span.start, \"token_end\":span.end, \"mention\":row[\"text\"][span.start_char:span.end_char], \"label\": entity} for span in sent_nlp.ents]\n",
    "        if \"spans\" in row:\n",
    "            row[\"spans\"] += ner_spans\n",
    "        else:\n",
    "            row[\"spans\"] = ner_spans\n",
    "\n",
    "        row[\"_annotator_id\"] = \"NER\"\n",
    "        row[\"_session_id\"] = \"NER\"\n",
    "        annotated_data.append(row)\n",
    "\n",
    "    return(annotated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b3e32",
   "metadata": {},
   "source": [
    "#### module call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495080b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = srsly.read_jsonl(ee_input_path)\n",
    "\n",
    "sents_with_M = NER(m_ner_model_path, input_data, \"METHOD\")\n",
    "sents_with_A = NER(a_ner_model_path, sents_with_M, \"ACTIVITY\")\n",
    "sents_with_G = NER(g_ner_model_path, sents_with_A, \"GOAL\")\n",
    "\n",
    "srsly.write_jsonl(ee_output_path, sents_with_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6afe7",
   "metadata": {},
   "source": [
    "### Entity Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde31975",
   "metadata": {},
   "source": [
    "#### module initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fabd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from zshot import PipelineConfig, MentionsExtractor\n",
    "from zshot.linker import LinkerRegen\n",
    "from zshot.linker.linker_regen.utils import load_wikipedia_trie\n",
    "from zshot.utils.mappings import spans_to_wikipedia\n",
    "from zshot.utils.data_models import Span\n",
    "import srsly\n",
    "from tqdm import tqdm\n",
    "import ssl\n",
    "import logging\n",
    "\n",
    "# If you want to disable warnings (let only the ERRORs pass) uncomment the following line:\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "# To use unverified ssl you can add this to your code:\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# Load the Wikipedia trie\n",
    "wikipedia_trie = load_wikipedia_trie()\n",
    "\n",
    "# Setup input and output paths\n",
    "ed_input_path = \"./Dataset/example_subset_20_EE.jsonl\"\n",
    "ed_output_path = \"./Dataset/example_subset_20_EE_ED.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b2ac6",
   "metadata": {},
   "source": [
    "#### module functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1ed143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMentionExtractor(MentionsExtractor):\n",
    "    def __init__(self, positions):\n",
    "        self.positions = positions\n",
    "    def predict(self, docs, batch_size=None):\n",
    "        # Returns the character indexes of the mention spans for every text as spaCy Span object\n",
    "        return [[Span(start, end) for start, end in self.positions] for _ in docs]\n",
    "\n",
    "# Function to run Entity Disambiguation\n",
    "def genre_wikipedia(text, start, end):\n",
    "    nlp_wikipedia = spacy.load(\"en_core_web_sm\")\n",
    "    nlp_config = PipelineConfig(\n",
    "        mentions_extractor=SimpleMentionExtractor([(start,end)]),\n",
    "        linker=LinkerRegen(trie=wikipedia_trie)\n",
    "    )\n",
    "    nlp_wikipedia.add_pipe(\"zshot\", config=nlp_config, last=True)\n",
    "    doc = nlp_wikipedia(text)\n",
    "    # Extract Wikipedia IDs from the spans after the entity linking, if no valid ID is found, return \"NIL\"\n",
    "    wikipedia_id = [i if i and \"=\" in i else \"NIL\" for i in spans_to_wikipedia(doc._.spans)]\n",
    "    return wikipedia_id[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f7b241",
   "metadata": {},
   "source": [
    "#### module call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89000a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(srsly.read_jsonl(ed_input_path))\n",
    "for item in tqdm(data):\n",
    "    text = item.get(\"text\")\n",
    "    for span in item.get(\"spans\", []):\n",
    "        if span.get(\"label\") == \"METHOD\":\n",
    "            span[\"wikipedia_url\"] = genre_wikipedia(text, span[\"start_char\"], span[\"end_char\"])\n",
    "\n",
    "srsly.write_jsonl(ed_output_path, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8a567",
   "metadata": {},
   "source": [
    "### Entity Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891e93f",
   "metadata": {},
   "source": [
    "#### module initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f43d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from tqdm import tqdm\n",
    "from linking_information_queries.information_linking_orcid import information_linking_orcid\n",
    "from linking_information_queries.information_linking_apis import information_linking\n",
    "\n",
    "# Setup input and output paths\n",
    "el_input_path = \"./Dataset/example_subset_20_EE_ED.jsonl\"\n",
    "el_output_path = \"./Dataset/example_subset_20_EE_ED_EL.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b189bc8",
   "metadata": {},
   "source": [
    "#### module functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f114fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_author_info(l_row):\n",
    "    author_list = []\n",
    "    for a in l_row.get(\"meta\").get(\"creator\", []):\n",
    "        # Retrieve the first and last name of the author\n",
    "        # Check if the first word is bigger than two characters\n",
    "        f_name = a.split()[0].strip()\n",
    "        l_name = a.split()[-1].strip()\n",
    "\n",
    "        try:\n",
    "            orcid_info = information_linking_orcid(f_name, l_name)\n",
    "            author_list.append({'full_name':a, 'given_name': orcid_info['given-names'], 'family_name':orcid_info['family-names'], 'orcid': orcid_info['orcid-id'], 'affiliations':orcid_info['institution-name'], 'email':orcid_info['email']})\n",
    "        except:\n",
    "            author_list.append({'full_name':a, 'given_name': f_name.capitalize(), 'family_name':l_name.capitalize(), 'orcid': 'None', 'affiliations':'None', 'email':'None'})\n",
    "    l_row['meta']['creator'] = author_list\n",
    "    \n",
    "    return(l_row)\n",
    "\n",
    "def link_method_info(l_row):\n",
    "    for label in l_row.get(\"spans\", []):\n",
    "        if label.get(\"label\") == \"METHOD\":\n",
    "            method_info = information_linking(wikipedia_url=label[\"wikipedia_url\"])\n",
    "\n",
    "            label[\"description\"] = method_info[\"description\"]\n",
    "            label[\"proper_name\"] = method_info[\"label\"]\n",
    "            label[\"aliases\"] = method_info[\"aliases\"]\n",
    "            label[\"wikidata_url\"] = method_info[\"wikidata\"]\n",
    "            label[\"dbpedia_url\"] = method_info[\"dbpedia\"]\n",
    "\n",
    "    return(l_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9420d2f9",
   "metadata": {},
   "source": [
    "#### module call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ae260",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = list(srsly.read_jsonl(el_input_path))\n",
    "linked_data = []\n",
    "\n",
    "for row in tqdm(in_data):\n",
    "    row = link_author_info(row)\n",
    "    row = link_method_info(row)\n",
    "    linked_data.append(row)\n",
    "\n",
    "srsly.write_jsonl(el_output_path, linked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bea5a2",
   "metadata": {},
   "source": [
    "### Relation Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d324f02b",
   "metadata": {},
   "source": [
    "#### module initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6d9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup input and output paths\n",
    "re_input_path = \"./Dataset/example_subset_20_EE_ED_EL.jsonl\"\n",
    "re_output_path = \"./Dataset/example_subset_20_EE_ED_EL_RE.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1499f973",
   "metadata": {},
   "source": [
    "#### module functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_overlapping(a_start, a_end, m_start, m_end):\n",
    "    return max(a_start, m_start) < min(a_end, m_end)\n",
    "\n",
    "def relation_extraction_employs(spans, text):\n",
    "    activity_list = []\n",
    "    methods_list = []\n",
    "    for span in spans:\n",
    "      if span.get(\"label\") == \"ACTIVITY\":\n",
    "        activity_list.append((span.get(\"start_char\"), span.get(\"end_char\"), span.get(\"label\"), text))\n",
    "      if span.get(\"label\") == \"METHOD\":\n",
    "        methods_list.append((span.get(\"start_char\"), span.get(\"end_char\"), span.get(\"label\")))\n",
    "\n",
    "    relation = []\n",
    "    for domain in activity_list:\n",
    "      activity_begin_num = domain[0]\n",
    "      activity_end_num = domain[1]\n",
    "      for range in methods_list:\n",
    "        method_begin_num = range[0]\n",
    "        method_end_num = range[1]\n",
    "        if is_overlapping(activity_begin_num, activity_end_num, method_begin_num, method_end_num):\n",
    "          relation.append({\"domain\":{\"start_char\":activity_begin_num, \"end_char\":activity_end_num, \"span\":domain[3][activity_begin_num:activity_end_num],\"label\":domain[2]}, \n",
    "                           \"range\":{\"start_char\":method_begin_num, \"end_char\":method_end_num, \"span\":domain[3][method_begin_num:method_end_num], \"label\":range[2]},\n",
    "                           \"label\":\"EMPLOYS\"})\n",
    "    return relation\n",
    "\n",
    "def relation_extraction_hasObjective(spans, text):\n",
    "    activity_list = []\n",
    "    goal_list = []\n",
    "    for span in spans:\n",
    "      if span.get(\"label\") == \"ACTIVITY\":\n",
    "        activity_list.append((span.get(\"start_char\"), span.get(\"end_char\"), span.get(\"label\"), text))\n",
    "      if span.get(\"label\") == \"GOAL\":\n",
    "        goal_list.append((span.get(\"start_char\"), span.get(\"end_char\"), span.get(\"label\")))\n",
    "\n",
    "    relation = []\n",
    "    for domain in activity_list:\n",
    "      activity_begin_num = domain[0]\n",
    "      activity_end_num = domain[1]\n",
    "      for range in goal_list:\n",
    "        goal_begin_num = range[0]\n",
    "        goal_end_num = range[1]\n",
    "        relation.append({\"domain\":{\"start_char\":activity_begin_num, \"end_char\":activity_end_num, \"span\":domain[3][activity_begin_num:activity_end_num],\"label\":domain[2]}, \n",
    "                        \"range\":{\"start_char\":goal_begin_num, \"end_char\":goal_end_num, \"span\":domain[3][goal_begin_num:goal_end_num], \"label\":range[2]},\n",
    "                        \"label\":\"HAS_OBJECTIVE\"})\n",
    "    return relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16edd5fd",
   "metadata": {},
   "source": [
    "#### module call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(srsly.read_jsonl(re_input_path))\n",
    "for i in tqdm(data):\n",
    "  text = i.get(\"text\")\n",
    "  spans = i.get(\"spans\")\n",
    "  checker = []\n",
    "  relations_employs = []\n",
    "  relations_hasObjective = []\n",
    "  for span in spans:\n",
    "    checker.append(span.get(\"label\"))\n",
    "  if \"ACTIVITY\" in checker and \"METHOD\" in checker:\n",
    "    relations_employs = relation_extraction_employs(spans, text)\n",
    "  if \"ACTIVITY\" in checker and \"GOAL\" in checker:\n",
    "    relations_hasObjective = relation_extraction_hasObjective(spans, text)\n",
    "  i[\"relations\"] = relations_employs + relations_hasObjective \n",
    "\n",
    "srsly.write_jsonl(re_output_path, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
