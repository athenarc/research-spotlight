{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "h8oCDc1cDwEu",
      "metadata": {
        "id": "h8oCDc1cDwEu"
      },
      "source": [
        "# Research Spotlight Demo (Google Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X0amNSf1MO1O",
      "metadata": {
        "id": "X0amNSf1MO1O"
      },
      "source": [
        "### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Cz8oTI1Xkif",
      "metadata": {
        "id": "9Cz8oTI1Xkif"
      },
      "outputs": [],
      "source": [
        "# Around 2 - 5 minutes depending on the internet connection speed\n",
        "# If you can, switch to GPU for faster inference (Change runtime -> T4 GPU -> Connect)\n",
        "%%capture\n",
        "!pip install -r \"https://raw.githubusercontent.com/athenarc/research-spotlight/refs/heads/main/MLE/requirements.txt\"\n",
        "\n",
        "# Google Colab setup\n",
        "import os\n",
        "os.makedirs(\"Dataset\", exist_ok=True)\n",
        "!wget https://raw.githubusercontent.com/athenarc/research-spotlight/refs/heads/main/MLE/example_subset_10.jsonl -P /content/Dataset\n",
        "!wget https://huggingface.co/facebook/genre-linking-blink/raw/main/trie.py\n",
        "!wget https://huggingface.co/facebook/genre-linking-blink/resolve/main/kilt_titles_trie_dict.pkl -P /content/Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfcd5438",
      "metadata": {
        "id": "dfcd5438"
      },
      "source": [
        "### Entity Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6dc4ad1",
      "metadata": {
        "id": "e6dc4ad1"
      },
      "source": [
        "#### Module initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8262eff0",
      "metadata": {
        "id": "8262eff0"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import srsly\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup module paths\n",
        "m_ner_model_path = \"en_deberta_v3_base_ner_method\"\n",
        "a_ner_model_path = \"en_deberta_v3_base_ner_activity\"\n",
        "g_ner_model_path = \"en_deberta_v3_base_ner_goal\"\n",
        "\n",
        "# Setup input and output paths\n",
        "ee_input_path = \"./Dataset/example_subset_10.jsonl\"\n",
        "ee_output_path = \"./Dataset/example_subset_10_EE.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d66cfd1f",
      "metadata": {
        "id": "d66cfd1f"
      },
      "source": [
        "#### Module functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f09eaa",
      "metadata": {
        "id": "16f09eaa"
      },
      "outputs": [],
      "source": [
        "def NER(model_path, in_data, entity):\n",
        "    print(\"NER for:\", entity)\n",
        "    ner_model = spacy.load(model_path)\n",
        "    annotated_data = []\n",
        "    for row in tqdm(in_data):\n",
        "        sent_nlp = ner_model(row[\"text\"])\n",
        "        ner_spans = [{\"start\": span.start_char, \"end\": span.end_char, \"token_start\":span.start, \"token_end\":span.end, \"mention\":row[\"text\"][span.start_char:span.end_char], \"label\": entity} for span in sent_nlp.ents]\n",
        "        if \"spans\" in row:\n",
        "            row[\"spans\"] += ner_spans\n",
        "        else:\n",
        "            row[\"spans\"] = ner_spans\n",
        "\n",
        "        row[\"_annotator_id\"] = \"NER\"\n",
        "        row[\"_session_id\"] = \"NER\"\n",
        "        annotated_data.append(row)\n",
        "\n",
        "    return(annotated_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6b3e32",
      "metadata": {
        "id": "7e6b3e32"
      },
      "source": [
        "#### Module call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "495080b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "495080b9",
        "outputId": "7a17437b-4858-4e59-acd5-37d993b50e4e"
      },
      "outputs": [],
      "source": [
        "input_data = srsly.read_jsonl(ee_input_path)\n",
        "\n",
        "sents_with_M = NER(m_ner_model_path, input_data, \"METHOD\")\n",
        "sents_with_A = NER(a_ner_model_path, sents_with_M, \"ACTIVITY\")\n",
        "sents_with_G = NER(g_ner_model_path, sents_with_A, \"GOAL\")\n",
        "\n",
        "srsly.write_jsonl(ee_output_path, sents_with_G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vOOcmlltGUtp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "vOOcmlltGUtp",
        "outputId": "52d3793c-6cf6-4326-a6b0-d133d5660a09"
      },
      "outputs": [],
      "source": [
        "# EXAMPLE: Visualize the NER\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.tokens import Span\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(sents_with_G[5][\"text\"])\n",
        "\n",
        "doc.spans[\"sc\"] = [\n",
        "    Span(doc, sents_with_G[5][\"spans\"][0][\"token_start\"], sents_with_G[5][\"spans\"][0][\"token_end\"], sents_with_G[5][\"spans\"][0][\"label\"]),\n",
        "    Span(doc, sents_with_G[5][\"spans\"][1][\"token_start\"], sents_with_G[5][\"spans\"][1][\"token_end\"], sents_with_G[5][\"spans\"][1][\"label\"]),\n",
        "    Span(doc, sents_with_G[5][\"spans\"][2][\"token_start\"], sents_with_G[5][\"spans\"][2][\"token_end\"], sents_with_G[5][\"spans\"][2][\"label\"])\n",
        "]\n",
        "\n",
        "colors = {\"METHOD\":\"cyan\", \"ACTIVITY\":\"orange\",\"GOAL\":\"lime\"}\n",
        "options = {\"colors\": colors}\n",
        "\n",
        "displacy.render(doc, jupyter=True, style=\"span\", options=options)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c6afe7",
      "metadata": {
        "id": "18c6afe7"
      },
      "source": [
        "### Entity Disambiguation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde31975",
      "metadata": {
        "id": "cde31975"
      },
      "source": [
        "#### Module initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C3JNoUdXBMQl",
      "metadata": {
        "id": "C3JNoUdXBMQl"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import pickle\n",
        "from trie import Trie\n",
        "import warnings\n",
        "import requests\n",
        "import uuid\n",
        "import os\n",
        "from transformers import logging\n",
        "\n",
        "# Disable HuggingFace & hub progress bars\n",
        "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
        "logging.disable_progress_bar()\n",
        "logging.set_verbosity_error()\n",
        "\n",
        "# Suppress output warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub.utils._auth\")\n",
        "\n",
        "# Load Wikipedia trie\n",
        "with open(\"/content/Dataset/kilt_titles_trie_dict.pkl\", \"rb\") as f:\n",
        "    trie = Trie.load_from_dict(pickle.load(f))\n",
        "\n",
        "# Setup input and output paths\n",
        "ed_input_path = \"./Dataset/example_subset_10_EE.jsonl\"\n",
        "ed_output_path = \"./Dataset/example_subset_10_EE_ED.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44b2ac6",
      "metadata": {
        "id": "d44b2ac6"
      },
      "source": [
        "#### Module functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1ed143",
      "metadata": {
        "id": "8d1ed143"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/genre-linking-blink\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/genre-linking-blink\").eval()\n",
        "\n",
        "headers = {\"User-Agent\": f\"GenreDisambiguationBot/1.0 (id={uuid.uuid4()})\"}\n",
        "\n",
        "def safe_prefix_fn(batch_id, sent):\n",
        "    allowed = trie.get(sent.tolist())\n",
        "\n",
        "    if not allowed:\n",
        "        # fallback: allow EOS so this beam can terminate\n",
        "        return [tokenizer.eos_token_id]\n",
        "\n",
        "    return allowed\n",
        "\n",
        "def genre_entity_disambiguation(model, tokenizer, text, start, end):\n",
        "  sentence = [text[:start] + \"[START_ENT] \" + text[start:end] + \" [END_ENT]\" + text[end:]]\n",
        "  outputs = model.generate(\n",
        "    **tokenizer(sentence, return_tensors=\"pt\"),\n",
        "    num_beams=5,\n",
        "    num_return_sequences=1,\n",
        "    prefix_allowed_tokens_fn=safe_prefix_fn\n",
        "  )\n",
        "\n",
        "  url = f\"https://en.wikipedia.org/w/api.php?action=query&prop=info&inprop=subjectid&titles={tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]}&format=json\"\n",
        "  json_response = requests.get(url, headers=headers).json()\n",
        "\n",
        "  return f\"https://en.wikipedia.org/wiki?curid={list(json_response[\"query\"][\"pages\"].keys())[0]}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9f7b241",
      "metadata": {
        "id": "b9f7b241"
      },
      "source": [
        "#### Module call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89000a7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89000a7e",
        "outputId": "20bcb85c-ab48-4555-9539-09f9ca6c1037"
      },
      "outputs": [],
      "source": [
        "# Around 5 minutes\n",
        "data = list(srsly.read_jsonl(ed_input_path))\n",
        "for item in tqdm(data):\n",
        "    text = item.get(\"text\")\n",
        "    for span in item.get(\"spans\", []):\n",
        "        if span.get(\"label\") == \"METHOD\":\n",
        "            span[\"wikipedia_url\"] = genre_entity_disambiguation(model, tokenizer, text, span[\"start\"], span[\"end\"])\n",
        "\n",
        "srsly.write_jsonl(ed_output_path, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27d8a567",
      "metadata": {
        "id": "27d8a567"
      },
      "source": [
        "### Entity Linking"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e891e93f",
      "metadata": {
        "id": "e891e93f"
      },
      "source": [
        "#### Module initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f43d01b",
      "metadata": {
        "id": "8f43d01b"
      },
      "outputs": [],
      "source": [
        "import srsly\n",
        "from tqdm import tqdm\n",
        "from information_linking_queries.information_linking_orcid import information_linking_orcid\n",
        "from information_linking_queries.information_linking_apis import information_linking\n",
        "\n",
        "# Setup input and output paths\n",
        "el_input_path = \"./Dataset/example_subset_10_EE_ED.jsonl\"\n",
        "el_output_path = \"./Dataset/example_subset_10_EE_ED_EL.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b189bc8",
      "metadata": {
        "id": "1b189bc8"
      },
      "source": [
        "#### Module functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f114fe",
      "metadata": {
        "id": "16f114fe"
      },
      "outputs": [],
      "source": [
        "def link_author_info(l_row):\n",
        "    author_list = []\n",
        "    for a in l_row.get(\"meta\").get(\"creator\", []):\n",
        "        # Retrieve the first and last name of the author\n",
        "        # Check if the first word is bigger than two characters\n",
        "        f_name = a.split()[0].strip()\n",
        "        l_name = a.split()[-1].strip()\n",
        "\n",
        "        try:\n",
        "            orcid_info = information_linking_orcid(f_name, l_name)\n",
        "            author_list.append({'full_name':a, 'given_name': orcid_info['given-names'], 'family_name':orcid_info['family-names'], 'orcid': orcid_info['orcid-id'], 'affiliations':orcid_info['institution-name'], 'email':orcid_info['email']})\n",
        "        except:\n",
        "            author_list.append({'full_name':a, 'given_name': f_name.capitalize(), 'family_name':l_name.capitalize(), 'orcid': 'None', 'affiliations':'None', 'email':'None'})\n",
        "    l_row['meta']['creator'] = author_list\n",
        "\n",
        "    return(l_row)\n",
        "\n",
        "def link_method_info(l_row):\n",
        "    for label in l_row.get(\"spans\", []):\n",
        "        if label.get(\"label\") == \"METHOD\":\n",
        "            method_info = information_linking(wikipedia_url=label[\"wikipedia_url\"])\n",
        "\n",
        "            label[\"description\"] = method_info[\"description\"]\n",
        "            label[\"proper_name\"] = method_info[\"label\"]\n",
        "            label[\"aliases\"] = method_info[\"aliases\"]\n",
        "            label[\"wikidata_url\"] = method_info[\"wikidata\"]\n",
        "            label[\"dbpedia_url\"] = method_info[\"dbpedia\"]\n",
        "\n",
        "    return(l_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9420d2f9",
      "metadata": {
        "id": "9420d2f9"
      },
      "source": [
        "#### Module call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370ae260",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "370ae260",
        "outputId": "1d1246a6-0f0f-4d6a-88bf-4aa98735008d"
      },
      "outputs": [],
      "source": [
        "in_data = list(srsly.read_jsonl(el_input_path))\n",
        "linked_data = []\n",
        "\n",
        "for row in tqdm(in_data):\n",
        "    row = link_author_info(row)\n",
        "    row = link_method_info(row)\n",
        "    linked_data.append(row)\n",
        "\n",
        "srsly.write_jsonl(el_output_path, linked_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6boCjLKL5in-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "6boCjLKL5in-",
        "outputId": "6dc3c10b-50af-412b-af4b-1cf8d1c5613e"
      },
      "outputs": [],
      "source": [
        "# Visualize the Entity Disambiguation for methods\n",
        "from spacy import displacy\n",
        "\n",
        "example = [{\"text\": linked_data[6][\"text\"],\n",
        "            \"ents\": [{\"start\": linked_data[6][\"spans\"][0][\"start\"], \"end\": linked_data[6][\"spans\"][0][\"end\"], \"label\": linked_data[6][\"spans\"][0][\"label\"], \"kb_id\": linked_data[6][\"spans\"][0][\"wikidata_url\"].split(\"/\")[-1], \"kb_url\": linked_data[6][\"spans\"][0][\"wikidata_url\"]},\n",
        "                     {\"start\": linked_data[6][\"spans\"][1][\"start\"], \"end\": linked_data[6][\"spans\"][1][\"end\"], \"label\": linked_data[6][\"spans\"][1][\"label\"], \"kb_id\": linked_data[6][\"spans\"][0][\"wikidata_url\"].split(\"/\")[-1], \"kb_url\": linked_data[6][\"spans\"][0][\"wikidata_url\"]},\n",
        "                     {\"start\": linked_data[6][\"spans\"][2][\"start\"], \"end\": linked_data[6][\"spans\"][2][\"end\"], \"label\": linked_data[6][\"spans\"][2][\"label\"], \"kb_id\": linked_data[6][\"spans\"][0][\"wikidata_url\"].split(\"/\")[-1], \"kb_url\": linked_data[6][\"spans\"][0][\"wikidata_url\"]}]}]\n",
        "\n",
        "options = {\"colors\": {\"METHOD\":\"cyan\"}}\n",
        "\n",
        "displacy.render(example, style=\"ent\", jupyter=True, manual=True, options=options)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0bea5a2",
      "metadata": {
        "id": "a0bea5a2"
      },
      "source": [
        "### Relation Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d324f02b",
      "metadata": {
        "id": "d324f02b"
      },
      "source": [
        "#### Module initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d6d9cb5",
      "metadata": {
        "id": "3d6d9cb5"
      },
      "outputs": [],
      "source": [
        "# Setup input and output paths\n",
        "re_input_path = \"./Dataset/example_subset_10_EE_ED_EL.jsonl\"\n",
        "re_output_path = \"./Dataset/example_subset_10_EE_ED_EL_RE.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1499f973",
      "metadata": {
        "id": "1499f973"
      },
      "source": [
        "#### Module functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a63c885",
      "metadata": {
        "id": "6a63c885"
      },
      "outputs": [],
      "source": [
        "def is_overlapping(a_start, a_end, m_start, m_end):\n",
        "    return max(a_start, m_start) < min(a_end, m_end)\n",
        "\n",
        "def relation_extraction_employs(spans):\n",
        "    activity_list = []\n",
        "    methods_list = []\n",
        "    for span in spans:\n",
        "      if span.get(\"label\") == \"ACTIVITY\":\n",
        "        activity_list.append((span.get(\"start\"), span.get(\"end\"), span.get(\"label\"), span.get(\"token_start\"), span.get(\"token_end\")))\n",
        "      if span.get(\"label\") == \"METHOD\":\n",
        "        methods_list.append((span.get(\"start\"), span.get(\"end\"), span.get(\"label\"), span.get(\"token_start\"), span.get(\"token_end\")))\n",
        "\n",
        "    relation = []\n",
        "    for domain in activity_list:\n",
        "      activity_begin_num = domain[0]\n",
        "      activity_end_num = domain[1]\n",
        "\n",
        "      activity_char_start = domain[-2]\n",
        "      activity_char_end = domain[-1]\n",
        "\n",
        "      for range in methods_list:\n",
        "        method_begin_num = range[0]\n",
        "        method_end_num = range[1]\n",
        "\n",
        "        method_char_start = range[-2]\n",
        "        method_char_end = range[-1]\n",
        "        if is_overlapping(activity_begin_num, activity_end_num, method_begin_num, method_end_num):\n",
        "          relation.append({\"domain\":{\"start\":activity_char_start, \"end\":activity_char_end,\"label\":domain[2]},\n",
        "                           \"range\":{\"start\":method_char_start, \"end\":method_char_end, \"label\":range[2]},\n",
        "                           \"label\":\"EMPLOYS\"})\n",
        "    return relation\n",
        "\n",
        "def relation_extraction_hasObjective(spans):\n",
        "    activity_list = []\n",
        "    goal_list = []\n",
        "    for span in spans:\n",
        "      if span.get(\"label\") == \"ACTIVITY\":\n",
        "        activity_list.append((span.get(\"start\"), span.get(\"end\"), span.get(\"label\"), span.get(\"token_start\"), span.get(\"token_end\")))\n",
        "      if span.get(\"label\") == \"GOAL\":\n",
        "        goal_list.append((span.get(\"start\"), span.get(\"end\"), span.get(\"label\"), span.get(\"token_start\"), span.get(\"token_end\")))\n",
        "\n",
        "    relation = []\n",
        "    for domain in activity_list:\n",
        "      activity_begin_num = domain[0]\n",
        "      activity_end_num = domain[1]\n",
        "\n",
        "      activity_char_start = domain[-2]\n",
        "      activity_char_end = domain[-1]\n",
        "\n",
        "      for range in goal_list:\n",
        "        goal_begin_num = range[0]\n",
        "        goal_end_num = range[1]\n",
        "\n",
        "        goal_char_start = domain[-2]\n",
        "        goal_char_end = domain[-1]\n",
        "        relation.append({\"domain\":{\"start\":activity_char_start, \"end\":activity_char_end, \"label\":domain[2]},\n",
        "                        \"range\":{\"start\":goal_char_start, \"end\":goal_char_end, \"label\":range[2]},\n",
        "                        \"label\":\"HAS_OBJECTIVE\"})\n",
        "    return relation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16edd5fd",
      "metadata": {
        "id": "16edd5fd"
      },
      "source": [
        "#### Module call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfa94c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cfa94c2",
        "outputId": "e41efeda-199f-477a-9fba-1f7607d8b645"
      },
      "outputs": [],
      "source": [
        "data = list(srsly.read_jsonl(re_input_path))\n",
        "for i in tqdm(data):\n",
        "  spans = i.get(\"spans\")\n",
        "  checker = []\n",
        "  relations_employs = []\n",
        "  relations_hasObjective = []\n",
        "  for span in spans:\n",
        "    checker.append(span.get(\"label\"))\n",
        "  if \"ACTIVITY\" in checker and \"METHOD\" in checker:\n",
        "    relations_employs = relation_extraction_employs(spans)\n",
        "  if \"ACTIVITY\" in checker and \"GOAL\" in checker:\n",
        "    relations_hasObjective = relation_extraction_hasObjective(spans)\n",
        "  i[\"relations\"] = relations_employs + relations_hasObjective\n",
        "\n",
        "srsly.write_jsonl(re_output_path, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cwcHzSXz3q58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "cwcHzSXz3q58",
        "outputId": "f45aae78-13d7-470f-f6a5-353bb3db0df9"
      },
      "outputs": [],
      "source": [
        "# Visualize the Relation Extraction module [WORK IN PROGRESS, MAY CHANGE]\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.tokens import Span\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(data[3][\"text\"])\n",
        "\n",
        "doc.spans[\"sc\"] = [\n",
        "    Span(doc, data[3][\"relations\"][0][\"domain\"][\"start\"], data[3][\"relations\"][0][\"domain\"][\"end\"], data[3][\"relations\"][0][\"domain\"][\"label\"]),\n",
        "    Span(doc, data[3][\"relations\"][0][\"range\"][\"start\"], data[3][\"relations\"][0][\"range\"][\"end\"], data[3][\"relations\"][0][\"range\"][\"label\"]),\n",
        "    Span(doc, data[3][\"relations\"][0][\"domain\"][\"start\"], data[3][\"relations\"][0][\"domain\"][\"end\"], data[3][\"relations\"][0][\"label\"])\n",
        "]\n",
        "\n",
        "colors = {\"METHOD\":\"cyan\", \"ACTIVITY\":\"orange\", \"EMPLOYS\":\"lime\"}\n",
        "options = {\"colors\": colors}\n",
        "\n",
        "displacy.render(doc, jupyter=True, style=\"span\", options=options)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6W4sZumUF0CO",
      "metadata": {
        "id": "6W4sZumUF0CO"
      },
      "source": [
        "### RDF conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kIcI1OxrF7h9",
      "metadata": {
        "id": "kIcI1OxrF7h9"
      },
      "source": [
        "#### Module initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OGxJcIEnGCZB",
      "metadata": {
        "id": "OGxJcIEnGCZB"
      },
      "outputs": [],
      "source": [
        "import srsly\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import requests\n",
        "from rdflib import Graph, Namespace, RDF, URIRef, RDFS, Literal, OWL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yX6Y6Vj6MLnl",
      "metadata": {
        "id": "yX6Y6Vj6MLnl"
      },
      "source": [
        "#### Module functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91APlxspMQEF",
      "metadata": {
        "id": "91APlxspMQEF"
      },
      "outputs": [],
      "source": [
        "def create_sentence_triples(jstor_row, article_uri, schema_ns, instances_ns, GraphObject):\n",
        "    query = \"\"\"\n",
        "              PREFIX so: <https://scholarlyontology.aueb.gr/resources/so_schema/so_jstor_1.0#>\n",
        "              SELECT DISTINCT ?m_name\n",
        "              WHERE {\n",
        "                  ?m_name rdf:type so:Sentence.\n",
        "              }\n",
        "            \"\"\"\n",
        "\n",
        "    s_list = [i[0] for i in GraphObject.query(query)]\n",
        "\n",
        "    #print('article id:', re.sub('.*/','',jstor_row['meta']['id']))\n",
        "    sent_uri = str(instances_ns)+'Sentence/'+str(row['meta']['sent_no'])\n",
        "    if URIRef(sent_uri) not in s_list:\n",
        "        GraphObject.add((URIRef(sent_uri), RDF.type, schema_ns.Sentence))\n",
        "        GraphObject.add((URIRef(sent_uri), schema_ns.sentence_text, Literal(jstor_row['text']) ))\n",
        "        GraphObject.add((URIRef(sent_uri), schema_ns.is_part_of, URIRef(article_uri) ))\n",
        "\n",
        "    return(GraphObject, sent_uri)\n",
        "\n",
        "\n",
        "def create_article_triples(jstor_row, schema_ns, instances_ns, GraphObject):\n",
        "    query = \"\"\"\n",
        "              PREFIX so: <https://scholarlyontology.aueb.gr/resources/so_schema/so_jstor_1.0#>\n",
        "              SELECT DISTINCT ?m_name\n",
        "              WHERE {\n",
        "                  ?m_name rdf:type so:Article.\n",
        "              }\n",
        "            \"\"\"\n",
        "\n",
        "    a_list = [i[0] for i in GraphObject.query(query)]\n",
        "\n",
        "    article_uri = str(instances_ns)+'Article/'+re.sub('.*/','',row['meta']['id'])\n",
        "\n",
        "    if URIRef(article_uri) not in a_list:\n",
        "        GraphObject.add((URIRef(article_uri), RDF.type, schema_ns.Article))\n",
        "        GraphObject.add((URIRef(article_uri), schema_ns.title, Literal(jstor_row['meta']['title']) ))\n",
        "        if 'url' in jstor_row['meta']:\n",
        "            GraphObject.add((URIRef(article_uri), schema_ns.article_URL, Literal(jstor_row['meta']['url']) ))\n",
        "\n",
        "        local_doi = None\n",
        "        for id_dict in jstor_row['meta'].get('identifier', []):\n",
        "            if id_dict.get('name') == 'local_doi':\n",
        "                local_doi = id_dict.get('value')\n",
        "                break\n",
        "        if local_doi:\n",
        "            GraphObject.add((URIRef(article_uri), schema_ns.article_DOI, Literal(local_doi)))\n",
        "\n",
        "        if 'datePublished' in jstor_row['meta']:\n",
        "            GraphObject.add((URIRef(article_uri), schema_ns.publication_date, Literal(jstor_row['meta']['datePublished']) ))\n",
        "        if 'publicationYear' in jstor_row['meta']:\n",
        "            GraphObject.add((URIRef(article_uri), schema_ns.publication_year, Literal(jstor_row['meta']['publicationYear']) ))\n",
        "        if 'issueNumber' in jstor_row['meta']:\n",
        "            GraphObject.add((URIRef(article_uri), schema_ns.issue_number, Literal(jstor_row['meta']['issueNumber']) ))\n",
        "        if 'publisher' in jstor_row['meta']:\n",
        "            GraphObject.add((URIRef(article_uri), schema_ns.publisher, Literal(jstor_row['meta']['publisher']) ))\n",
        "        if 'pageCount' in jstor_row['meta']:\n",
        "            GraphObject.add((URIRef(article_uri), schema_ns.page_count, Literal(jstor_row['meta']['pageCount']) ))\n",
        "        if 'docType' in jstor_row['meta']:\n",
        "            GraphObject.add((URIRef(article_uri), schema_ns.doctype, Literal(jstor_row['meta']['docType']) ))\n",
        "\n",
        "\n",
        "    return(GraphObject, article_uri)\n",
        "\n",
        "\n",
        "def create_aggregation_triples(jstor_row, article_uri, schema_ns, instances_ns, GraphObject):\n",
        "    query = \"\"\"\n",
        "            PREFIX so: <https://scholarlyontology.aueb.gr/resources/so_schema/so_jstor_1.0#>\n",
        "            SELECT DISTINCT ?m_name\n",
        "            WHERE {\n",
        "                ?m_name rdf:type so:Aggregation.\n",
        "            }\n",
        "            \"\"\"\n",
        "\n",
        "    a_list = [i[0] for i in GraphObject.query(query)]\n",
        "\n",
        "    aggregation_uri = str(instances_ns)+'Aggregation/'+re.sub(' ','_',jstor_row['meta']['isPartOf'])\n",
        "\n",
        "    if URIRef(aggregation_uri) not in a_list:\n",
        "        GraphObject.add((URIRef(aggregation_uri), RDF.type, schema_ns.Aggregation))\n",
        "        GraphObject.add((URIRef(aggregation_uri), schema_ns.aggregation_name, Literal(jstor_row['meta']['isPartOf']) ))\n",
        "\n",
        "    GraphObject.add((URIRef(article_uri), schema_ns.is_member_of, URIRef(aggregation_uri) ))\n",
        "\n",
        "    return(GraphObject)\n",
        "\n",
        "\n",
        "def create_topic_triples(jstor_row, article_uri, schema_ns, instances_ns, GraphObject):\n",
        "    query = \"\"\"\n",
        "              PREFIX so: <https://scholarlyontology.aueb.gr/resources/so_schema/so_jstor_1.0#>\n",
        "              SELECT DISTINCT ?m_name\n",
        "              WHERE {\n",
        "                  ?m_name rdf:type so:Topic.\n",
        "              }\n",
        "                \"\"\"\n",
        "\n",
        "    a_list = [i[0] for i in GraphObject.query(query)]\n",
        "\n",
        "    for t in jstor_row['meta']['topics']:\n",
        "        topic_uri = str(instances_ns)+'Topic/'+re.sub(' ','_',t)\n",
        "        if URIRef(topic_uri) not in a_list:\n",
        "            GraphObject.add((URIRef(topic_uri), RDF.type, schema_ns.Topic))\n",
        "            GraphObject.add((URIRef(topic_uri), schema_ns.topic_name, Literal(t) ))\n",
        "\n",
        "        GraphObject.add((URIRef(topic_uri), schema_ns.is_topic_of, URIRef(article_uri) ))\n",
        "\n",
        "    return(GraphObject)\n",
        "\n",
        "\n",
        "def create_author_organization_triples(jstor_row, article_uri, schema_ns, instances_ns, GraphObject):\n",
        "    query = \"\"\"\n",
        "              PREFIX so: <https://scholarlyontology.aueb.gr/resources/so_schema/so_jstor_1.0#>\n",
        "              SELECT DISTINCT ?m_name\n",
        "              WHERE {\n",
        "                  ?m_name rdf:type so:Person.\n",
        "              }\n",
        "              \"\"\"\n",
        "\n",
        "    p_list = [i[0] for i in GraphObject.query(query)]\n",
        "    query = \"\"\"\n",
        "              PREFIX so: <https://scholarlyontology.aueb.gr/resources/so_schema/so_jstor_1.0#>\n",
        "              SELECT DISTINCT ?m_name\n",
        "              WHERE {\n",
        "                  ?m_name rdf:type so:Organization.\n",
        "              }\n",
        "              \"\"\"\n",
        "\n",
        "    o_list = [i[0] for i in GraphObject.query(query)]\n",
        "\n",
        "    authors = []\n",
        "    for crt in jstor_row['meta']['creator']:\n",
        "        if crt['orcid'] != 'None':\n",
        "            author_uri = str(instances_ns)+'Person/'+str(crt['orcid'])\n",
        "            if URIRef(author_uri) not in p_list:\n",
        "                GraphObject.add((URIRef(author_uri), schema_ns.orcid, Literal(crt['orcid']) ))\n",
        "                GraphObject.add((URIRef(author_uri), RDF.type, schema_ns.Person))\n",
        "                GraphObject.add((URIRef(author_uri), schema_ns.full_name, Literal(crt['full_name']) ))\n",
        "                GraphObject.add((URIRef(author_uri), schema_ns.family_name, Literal(crt['family_name']) ))\n",
        "                GraphObject.add((URIRef(author_uri), schema_ns.given_name, Literal(crt['given_name']) ))\n",
        "\n",
        "                for org in crt['affiliations']:\n",
        "                    org_uri = str(instances_ns)+'Organization/'+re.sub(' ', '_', org)\n",
        "                    if URIRef(org_uri) not in o_list:\n",
        "                        GraphObject.add((URIRef(org_uri), RDF.type, schema_ns.Organization))\n",
        "                        GraphObject.add((URIRef(org_uri), schema_ns.organization_name, Literal(org) ))\n",
        "                    GraphObject.add((URIRef(author_uri), schema_ns.is_affiliated_to, URIRef(org_uri) ))\n",
        "\n",
        "        elif crt['orcid'] == 'None':\n",
        "            author_uri = str(instances_ns)+'Person/' + re.sub(' ','_',crt['full_name'])\n",
        "            if URIRef(author_uri) not in p_list:\n",
        "                GraphObject.add((URIRef(author_uri), RDF.type, schema_ns.Person))\n",
        "                GraphObject.add((URIRef(author_uri), schema_ns.full_name, Literal(crt['full_name']) ))\n",
        "                GraphObject.add((URIRef(author_uri), schema_ns.family_name, Literal(crt['family_name']) ))\n",
        "                GraphObject.add((URIRef(author_uri), schema_ns.given_name, Literal(crt['given_name']) ))\n",
        "\n",
        "        GraphObject.add((URIRef(author_uri), schema_ns.is_author_of, URIRef(article_uri) ))\n",
        "\n",
        "        authors.append(author_uri)\n",
        "\n",
        "    return(GraphObject, authors)\n",
        "\n",
        "\n",
        "def create_activity_triples(row, act_span, author_uris, sent_uri, schema_ns, instances_ns, GraphObject):\n",
        "    act_uri = str(instances_ns)+'Activity/'+str(row['meta']['sent_no'])+ '_'+ str(act_span['start'])+'_'+str(act_span['end'])\n",
        "    GraphObject.add((URIRef(act_uri), RDF.type, schema_ns.Activity))\n",
        "    GraphObject.add((URIRef(act_uri), schema_ns.textual_span, Literal(row['text'][act_span['start']:act_span['end']]) ))\n",
        "    GraphObject.add((URIRef(act_uri), schema_ns.has_sentence_context, URIRef(sent_uri) ))\n",
        "    GraphObject.add((URIRef(act_uri), schema_ns.begin_index, Literal(act_span['start']) ))\n",
        "    GraphObject.add((URIRef(act_uri), schema_ns.end_index, Literal(act_span['end']) ))\n",
        "    #GraphObject.add((URIRef(act_uri), schema_ns.has_article_context, URIRef(article_uri) ))\n",
        "    for a_uri in author_uris:\n",
        "        GraphObject.add((URIRef(a_uri), schema_ns.participates_in, URIRef(act_uri) ))\n",
        "\n",
        "    return(GraphObject)\n",
        "\n",
        "def create_goal_triples(row, g_span, author_uris, sent_uri, schema_ns, instances_ns, GraphObject):\n",
        "    goal_uri = str(instances_ns)+'Goal/'+str(row['meta']['sent_no'])+ '_'+ str(g_span['start'])+'_'+str(g_span['end'])\n",
        "    GraphObject.add((URIRef(goal_uri), RDF.type, schema_ns.Goal))\n",
        "    GraphObject.add((URIRef(goal_uri), schema_ns.textual_span, Literal(row['text'][g_span['start']:g_span['end']]) ))\n",
        "    GraphObject.add((URIRef(goal_uri), schema_ns.has_sentence_context, URIRef(sent_uri) ))\n",
        "    GraphObject.add((URIRef(goal_uri), schema_ns.begin_index, Literal(g_span['start']) ))\n",
        "    GraphObject.add((URIRef(goal_uri), schema_ns.end_index, Literal(g_span['end']) ))\n",
        "    #GraphObject.add((URIRef(goal_uri), schema_ns.has_article_context, URIRef(article_uri) ))\n",
        "    for a_uri in author_uris:\n",
        "        GraphObject.add((URIRef(a_uri), schema_ns.has_goal, URIRef(goal_uri) ))\n",
        "\n",
        "    return(GraphObject)\n",
        "\n",
        "\n",
        "def create_method_triples(m_span, sent_uri, sent_no, schema_ns, instances_ns, GraphObject, sentence_text):\n",
        "    \"\"\"\n",
        "    Create a unique Method node for each occurrence in a sentence.\n",
        "    \"\"\"\n",
        "    # Make URI unique per sentence & span\n",
        "    if 'qid' in m_span and m_span['qid'] != 'None':\n",
        "        m_uri = str(instances_ns) + 'Method/' + str(m_span['qid']) +\"_\"+ str(sent_no)+\"_\"+ str(m_span[\"start\"]) + \"_\"+ str(m_span[\"end\"])\n",
        "    else:\n",
        "        m_uri = str(instances_ns) + 'Method/' + re.sub(' ', '_', m_span['proper_name']) +\"_\"+ str(sent_no) +\"_\"+ str(m_span[\"start\"]) + \"_\"+ str(m_span[\"end\"])\n",
        "\n",
        "    # Create the node\n",
        "    GraphObject.add((URIRef(m_uri), RDF.type, schema_ns.Method))\n",
        "    GraphObject.add((URIRef(m_uri), schema_ns.method_name, Literal(str(m_span['proper_name']))))\n",
        "    GraphObject.add((URIRef(m_uri), schema_ns.textual_span, Literal(sentence_text[m_span['start']:m_span['end']])))\n",
        "    GraphObject.add((URIRef(m_uri), schema_ns.has_sentence_context, URIRef(sent_uri)))\n",
        "    #GraphObject.add((URIRef(m_uri), schema_ns.has_article_context, URIRef(article_uri)))\n",
        "\n",
        "    # Optional metadata\n",
        "    if 'wikidata_url' in m_span and m_span['wikidata_url'] not in [None, 'None']:\n",
        "        GraphObject.add((URIRef(m_uri), schema_ns.wikidata_url, Literal(str(m_span['wikidata_url']))))\n",
        "    if 'description' in m_span and m_span['description'] not in [None, 'None']:\n",
        "        GraphObject.add((URIRef(m_uri), schema_ns.description, Literal(str(m_span['description']))))\n",
        "    if 'aliases' in m_span and m_span['aliases'] not in [None, []]:\n",
        "        GraphObject.add((URIRef(m_uri), schema_ns.aliases, Literal(str(m_span['aliases']))))\n",
        "    if 'wikipedia_url' in m_span and m_span['wikipedia_url'] not in [None, 'None']:\n",
        "        GraphObject.add((URIRef(m_uri), schema_ns.wikipedia_url, Literal(str(m_span['wikipedia_url']))))\n",
        "    if 'qid' in m_span and m_span['qid'] != 'None':\n",
        "        GraphObject.add((URIRef(m_uri), schema_ns.qid, Literal(str(m_span['qid']))))\n",
        "\n",
        "    return m_uri, GraphObject\n",
        "\n",
        "\n",
        "def spans_overlap(start1, end1, start2, end2):\n",
        "    return not (end1 < start2 or end2 < start1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PD2vKEICJUpK",
      "metadata": {
        "id": "PD2vKEICJUpK"
      },
      "source": [
        "#### Schema decleration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5PyUom61HJQs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PyUom61HJQs",
        "outputId": "0a81b974-f0bd-4962-8bb0-866266d36fde"
      },
      "outputs": [],
      "source": [
        "schema_ns = Namespace(\"https://scholarlyontology.aueb.gr/resources/so_schema/so_MLE#\")\n",
        "instances_ns = Namespace(\"https://scholarlyontology.aueb.gr/resources/so_instances/so_MLE#\")\n",
        "nif_ns = Namespace(\"http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#\")\n",
        "\n",
        "g = Graph()\n",
        "\n",
        "g.bind(\"so\", schema_ns)\n",
        "g.bind(\"inst\", instances_ns)\n",
        "g.bind(\"nif\", nif_ns)\n",
        "\n",
        "\n",
        "# Classes\n",
        "def declare_class(cls, parent=None):\n",
        "    g.add((cls, RDF.type, RDFS.Class))\n",
        "    if parent:\n",
        "        g.add((cls, RDFS.subClassOf, parent))\n",
        "\n",
        "# Higher level\n",
        "declare_class(schema_ns.SO_Entity)\n",
        "declare_class(schema_ns.Object, schema_ns.SO_Entity)\n",
        "declare_class(schema_ns.ConceptualObject, schema_ns.Object)\n",
        "declare_class(schema_ns.InformationResource, schema_ns.ConceptualObject)\n",
        "declare_class(schema_ns.Assertion, schema_ns.ConceptualObject)\n",
        "declare_class(schema_ns.Event, schema_ns.SO_Entity)\n",
        "declare_class(schema_ns.Actor, schema_ns.SO_Entity)\n",
        "declare_class(schema_ns.Group, schema_ns.Actor)\n",
        "declare_class(schema_ns.ContentItem, schema_ns.InformationResource)\n",
        "\n",
        "# With instances\n",
        "declare_class(schema_ns.Activity, schema_ns.Event)\n",
        "declare_class(schema_ns.Method, schema_ns.ConceptualObject)\n",
        "declare_class(schema_ns.Topic, schema_ns.ConceptualObject)\n",
        "declare_class(schema_ns.Goal, schema_ns.Assertion)\n",
        "declare_class(schema_ns.Person, schema_ns.Actor)\n",
        "declare_class(schema_ns.Organization, schema_ns.Group)\n",
        "declare_class(schema_ns.Article, schema_ns.ContentItem)\n",
        "declare_class(schema_ns.Sentence, schema_ns.ContentItem)\n",
        "declare_class(schema_ns.Aggregation, schema_ns.InformationResource)\n",
        "\n",
        "\n",
        "# Object properties\n",
        "def declare_object_property(p, domain, range):\n",
        "    g.add((p, RDF.type, OWL.ObjectProperty))\n",
        "    g.add((p, RDFS.domain, domain))\n",
        "    g.add((p, RDFS.range, range))\n",
        "\n",
        "declare_object_property(schema_ns.employs, schema_ns.Activity, schema_ns.Method)\n",
        "declare_object_property(schema_ns.participates_in, schema_ns.Person, schema_ns.Activity)\n",
        "declare_object_property(schema_ns.has_goal, schema_ns.Person, schema_ns.Goal)\n",
        "declare_object_property(schema_ns.has_objective, schema_ns.Activity, schema_ns.Goal)\n",
        "declare_object_property(schema_ns.has_sentence_context, nif_ns.String, nif_ns.Context)\n",
        "declare_object_property(schema_ns.is_member_of, schema_ns.Article, schema_ns.Aggregation)\n",
        "declare_object_property(schema_ns.is_topic_of, schema_ns.Topic, schema_ns.Article)\n",
        "declare_object_property(schema_ns.uses_method, schema_ns.Person, schema_ns.Method)\n",
        "declare_object_property(schema_ns.is_part_of, schema_ns.Sentence, schema_ns.Article)\n",
        "declare_object_property(schema_ns.is_author_of, schema_ns.Person, schema_ns.Article)\n",
        "declare_object_property(schema_ns.is_affiliated_to, schema_ns.Person, schema_ns.Organization)\n",
        "\n",
        "\n",
        "# Datatype properties\n",
        "def declare_datatype_property(p, domain):\n",
        "    g.add((p, RDF.type, OWL.DatatypeProperty))\n",
        "    g.add((p, RDFS.domain, domain))\n",
        "\n",
        "declare_datatype_property(schema_ns.full_name, schema_ns.Person)\n",
        "declare_datatype_property(schema_ns.given_name, schema_ns.Person)\n",
        "declare_datatype_property(schema_ns.family_name, schema_ns.Person)\n",
        "declare_datatype_property(schema_ns.orcid, schema_ns.Person)\n",
        "\n",
        "declare_datatype_property(schema_ns.begin_index, nif_ns.String)\n",
        "declare_datatype_property(schema_ns.end_index, nif_ns.String)\n",
        "\n",
        "declare_datatype_property(schema_ns.publication_year, schema_ns.Article)\n",
        "declare_datatype_property(schema_ns.title, schema_ns.Article)\n",
        "declare_datatype_property(schema_ns.article_DOI, schema_ns.Article)\n",
        "\n",
        "declare_datatype_property(schema_ns.organization_name, schema_ns.Organization)\n",
        "declare_datatype_property(schema_ns.aggregation_name, schema_ns.Aggregation)\n",
        "\n",
        "declare_datatype_property(schema_ns.sentence_text, schema_ns.Sentence)\n",
        "declare_datatype_property(schema_ns.topic_name, schema_ns.Topic)\n",
        "\n",
        "declare_datatype_property(schema_ns.wikidata_url, schema_ns.Method)\n",
        "declare_datatype_property(schema_ns.qid, schema_ns.Method)\n",
        "\n",
        "\n",
        "# Save schema\n",
        "g.serialize(\"./Dataset/so_MLE_schema.rdf\", format=\"xml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KPN8NwwEMBBb",
      "metadata": {
        "id": "KPN8NwwEMBBb"
      },
      "source": [
        "#### Module call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aZgB2PhMAo1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aZgB2PhMAo1",
        "outputId": "32995a44-7214-4581-a8e3-9c14fb5a767c"
      },
      "outputs": [],
      "source": [
        "# Load schema\n",
        "g = Graph()\n",
        "g.parse(\"./Dataset/so_MLE_schema.rdf\", format=\"xml\")\n",
        "g.bind(\"so\", schema_ns)\n",
        "g.bind(\"inst\", instances_ns)\n",
        "g.bind(\"nif\", nif_ns)\n",
        "\n",
        "# Load file\n",
        "input_path = \"./Dataset/example_subset_10_EE_ED_EL_RE.jsonl\"\n",
        "in_data = srsly.read_jsonl(input_path)\n",
        "\n",
        "# Module call\n",
        "for row in tqdm(in_data):\n",
        "    if row[\"answer\"] == \"accept\" or row[\"answer\"] == \"ignore\":\n",
        "        activity_uris = []\n",
        "        goal_uris = []\n",
        "        method_uris = []\n",
        "        g, article_uri = create_article_triples(row, schema_ns, instances_ns, g)\n",
        "        g, sent_uri = create_sentence_triples(row, article_uri, schema_ns, instances_ns, g)\n",
        "        try:\n",
        "            g = create_aggregation_triples(row, article_uri, schema_ns, instances_ns, g)\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            g = create_topic_triples(row, article_uri, schema_ns, instances_ns, g)\n",
        "        except:\n",
        "            pass\n",
        "        g, author_uris = create_author_organization_triples(row, article_uri, schema_ns, instances_ns, g)\n",
        "\n",
        "        if len(row['spans']) >0:\n",
        "            for span in row['spans']:\n",
        "                if span['label'] == 'ACTIVITY':\n",
        "                    g = create_activity_triples(row, span, author_uris, sent_uri, schema_ns, instances_ns, g)\n",
        "                    activity_uri = str(instances_ns)+'Activity/'+str(row['meta']['sent_no'])+ '_'+ str(span['start'])+'_'+str(span['end'])\n",
        "                    activity_uris.append({'uri': activity_uri, 'span': span})\n",
        "                elif span['label'] == 'METHOD':\n",
        "                    method_uri, g = create_method_triples(span, sent_uri, row['meta']['sent_no'], schema_ns, instances_ns, g, row['text'])\n",
        "                    method_uris.append({'uri': method_uri, 'span': span})\n",
        "                elif span['label'] == 'GOAL':\n",
        "                    g = create_goal_triples(row, span, author_uris, sent_uri, schema_ns, instances_ns, g)\n",
        "                    goal_uri = str(instances_ns)+'Goal/'+str(row['meta']['sent_no'])+ '_'+ str(span['start'])+'_'+str(span['end'])\n",
        "                    goal_uris.append({'uri': goal_uri, 'span': span})\n",
        "\n",
        "            for act in activity_uris:\n",
        "                act_start, act_end = act['span']['start'], act['span']['end']\n",
        "\n",
        "                for meth in method_uris:\n",
        "                    m_start, m_end = meth['span']['start'], meth['span']['end']\n",
        "                    if spans_overlap(int(act_start), int(act_end), int(m_start), int(m_end)):\n",
        "                        g.add((URIRef(act['uri']), schema_ns.employs, URIRef(meth['uri'])))\n",
        "\n",
        "            for act in activity_uris:\n",
        "                act_uri = URIRef(act['uri'])\n",
        "                for goal in goal_uris:\n",
        "                    goal_uri = URIRef(goal['uri'])\n",
        "                    # If you want to restrict to overlapping spans, uncomment the if:\n",
        "                    # g_start, g_end = goal['span']['start'], goal['span']['end']\n",
        "                    # if spans_overlap(act['span']['start'], act['span']['end'], g_start, g_end):\n",
        "                    g.add((act_uri, schema_ns.has_objective, goal_uri))\n",
        "\n",
        "            for act in activity_uris:\n",
        "                act_uri = URIRef(act['uri'])\n",
        "                for meth in method_uris:\n",
        "                    meth_uri = URIRef(meth['uri'])\n",
        "                    if (act_uri, schema_ns.employs, meth_uri) in g:\n",
        "                        for person_uri in [p for p in author_uris if (URIRef(p), schema_ns.participates_in, act_uri) in g]:\n",
        "                            g.add((URIRef(person_uri), schema_ns.uses_method, meth_uri))\n",
        "\n",
        "# Save RDF file\n",
        "output_path = \"./Dataset/MLE_RDF.rdf\"\n",
        "g.serialize(destination=output_path, format='xml')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
